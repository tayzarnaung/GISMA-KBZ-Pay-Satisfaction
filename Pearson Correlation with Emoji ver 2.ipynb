{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c703206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from math import ceil\n",
    "import sys\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d5d7f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Unicode ranges for common emojis\n",
    "EMOJI_PATTERN = re.compile(\n",
    "    \"[\"\n",
    "    \"\\U0001F600-\\U0001F64F\"\n",
    "    \"\\U0001F300-\\U0001F5FF\"\n",
    "    \"\\U0001F680-\\U0001F6FF\"\n",
    "    \"\\U0001F700-\\U0001F77F\"\n",
    "    \"\\U0001F780-\\U0001F7FF\"\n",
    "    \"\\U0001F800-\\U0001F8FF\"\n",
    "    \"\\U0001F900-\\U0001F9FF\"\n",
    "    \"\\U0001FA00-\\U0001FA6F\"\n",
    "    \"\\U0001FA70-\\U0001FAFF\"\n",
    "    \"\\U00002702-\\U000027B0\"\n",
    "    \"\\U00002600-\\U000026FF\"\n",
    "    \"]+\", flags=re.UNICODE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a78bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature Engineering Functions ---\n",
    "\n",
    "def count_emojis(text):\n",
    "    \"\"\"Counts the number of emojis in a text string.\"\"\"\n",
    "    if pd.isna(text) or text is None: return 0\n",
    "    return len(EMOJI_PATTERN.findall(str(text)))\n",
    "\n",
    "def calculate_month_diff(date, start_date):\n",
    "    \"\"\"Calculates the total number of months between two datetime objects.\"\"\"\n",
    "    return (date.year - start_date.year) * 12 + (date.month - start_date.month)\n",
    "\n",
    "def get_language_type(text):\n",
    "    \"\"\"Categorizes review text into Burmese, English, or Mixed.\"\"\"\n",
    "    text = str(text)\n",
    "    # Check for Burmese characters (Unicode range U+1000 to U+109F)\n",
    "    is_burmese_present = any('\\u1000' <= char <= '\\u109F' for char in text)\n",
    "    # Check for English characters (ASCII letters a-z, A-Z)\n",
    "    is_english_present = any('a' <= char <= 'z' or 'A' <= char <= 'Z' for char in text)\n",
    "\n",
    "    if is_burmese_present and is_english_present:\n",
    "        return 'Mixed'\n",
    "    elif is_burmese_present:\n",
    "        return 'Burmese'\n",
    "    elif is_english_present:\n",
    "        return 'English'\n",
    "    else:\n",
    "        # Punctuation/numbers onlyâ€”default to English as it often represents short English reviews\n",
    "        return 'English'\n",
    "\n",
    "# --- Start of the actual analysis code ---\n",
    "file_path = \"KBZ_Pay_Translated_with_Sentiment.csv\"\n",
    "target_variable = 'Rating'\n",
    "sentiment_variable = 'Sentiment_Score_Translated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d7bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Data\n",
    "try:\n",
    "    # Use robust loading parameters for the user's uploaded CSV\n",
    "    df = pd.read_csv(file_path, encoding='utf-8-sig', on_bad_lines='skip', engine='python')\n",
    "except Exception as e:\n",
    "    # Handle error if file fails to load\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf6b079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "df = df.dropna(subset=[target_variable, 'Review', sentiment_variable])\n",
    "df[target_variable] = pd.to_numeric(df[target_variable], errors='coerce')\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df = df.dropna(subset=['Date', 'Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bffb71e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FEATURE ENGINEERING ---\n",
    "\n",
    "# 1. Language Categorization and OHE (For Lang_Burmese, Lang_English, Lang_Mixed)\n",
    "df['Language_Type'] = df['Review'].apply(get_language_type)\n",
    "language_dummies = pd.get_dummies(df['Language_Type'], prefix='Lang', drop_first=False)\n",
    "df = pd.concat([df, language_dummies], axis=1).drop(columns=['Language_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "526079af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 2-Month Interval (Ordinal Time Feature)\n",
    "start_date = df['Date'].min()\n",
    "df['Month_Difference'] = df['Date'].apply(lambda x: calculate_month_diff(x, start_date))\n",
    "df['Date_Interval'] = (df['Month_Difference'] / 2).apply(ceil).astype(int)\n",
    "\n",
    "# 3. Emoji Count (Continuous Feature)\n",
    "df['Emoji_Count'] = df['Review'].apply(count_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97acc119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Device Type OHE\n",
    "if 'Device Type' in df.columns:\n",
    "    device_dummies = pd.get_dummies(df['Device Type'], prefix='Device', drop_first=False)\n",
    "    df = pd.concat([df, device_dummies], axis=1).drop(columns=['Device Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd26c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Identify Final Variables for Correlation ---\n",
    "independent_vars = [\n",
    "    sentiment_variable,\n",
    "    'Date_Interval',\n",
    "    'Emoji_Count',\n",
    "]\n",
    "# Dynamically add all OHE columns\n",
    "independent_vars.extend([col for col in df.columns if col.startswith('Lang_')])\n",
    "independent_vars.extend([col for col in df.columns if col.startswith('Device_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46c53866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 5: Calculate the Pearson Correlation Matrix ---\n",
    "correlation_data = df[[target_variable] + independent_vars].dropna()\n",
    "correlation_matrix = correlation_data.corr(method='pearson')\n",
    "\n",
    "# --- Step 6: Extract and Present Results ---\n",
    "pearson_results = correlation_matrix.loc[target_variable, independent_vars].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24b81022",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'KBZ_Pay_Final_Correlation_Data_Ver2.csv'\n",
    "df.to_csv(output_file, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6693b760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "        FINAL PEARSON CORRELATION RESULTS (r)\n",
      "==================================================\n",
      "Sentiment_Score_Translated    0.4166\n",
      "Lang_English                  0.2390\n",
      "Emoji_Count                   0.0147\n",
      "Device_Tablet                 0.0032\n",
      "Device_Phone                 -0.0032\n",
      "Date_Interval                -0.0330\n",
      "Lang_Burmese                 -0.0730\n",
      "Lang_Mixed                   -0.2811\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# This print statement is optimized for clean, formatted output in a notebook cell\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"        FINAL PEARSON CORRELATION RESULTS (r)\")\n",
    "print(\"=\"*50)\n",
    "print(pearson_results.to_string(header=True, float_format=\"{:.4f}\".format))\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c5f672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
